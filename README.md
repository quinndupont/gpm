# Poetry Chatbot — Educator + Poet (v3)

Two-model poetry system: **Educator** (mentor/critic) + **Poet** (generator). Cloud training on Modal, local inference via llama.cpp (e.g. Mac). Training data via Claude API. See [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) for overview and [docs/DESIGN.md](docs/DESIGN.md) for full spec.

## Model choice

**Base: Qwen 2.5 7B Instruct** (`Qwen/Qwen2.5-7B-Instruct`). Apache 2.0 license, strong for nuanced text. Two Q4_K_M models (~4.5GB each) fit easily on 24GB Mac Mini.

## Setup

```bash
pip install -r requirements.txt
# .env: ANTHROPIC_API_KEY, HF_TOKEN (for Hugging Face model downloads)
modal token set
modal secret create huggingface-secret HF_TOKEN=your_token
```

## Data prep

Add raw poetry to `data/raw/good/` and `data/raw/bad/`. Format: `.json` or `.jsonl` with `{author, title, poem}` per item; `.txt` as plain poem. Contrastive learning: bad poems (~114) paired with good (~34k) for comparisons.

## Full pipeline

| Step | What | Anthropic | Local |
|------|------|-----------|-------|
| 1 | Hard tasks (critiques, comparisons, revision_briefs) | Opus (forced) | — |
| 2 | Train interim educator on seed | 0 | Modal GPU |
| 3 | Export + download interim educator | 0 | Modal + local |
| 4 | Local educator generates briefs, autopsies, lessons | 0 | llama.cpp |
| 5 | Poet pairs | Opus (forced) | — |
| 6 | Prepare full training data | 0 | Combines JSONL |
| 7 | Train final educator + poet | 0 | Modal GPU |
| 8 | Export + download final models | 0 | Modal + local |

**Anthropic for hard tasks only:** critiques, comparisons, revision_briefs, poet_pairs use Claude (force_anthropic, no local fallback). Briefs, autopsies, lessons are generated by the interim educator locally.

### 1. Data generation (Claude API)

**Hard tasks (Opus):**
| Script | Input | Output |
|--------|-------|--------|
| `generate_critiques_seed` | raw good + bad | critiques_seed.jsonl (all bad + 200 good) |
| `generate_comparisons` | good + bad pairs | comparisons.jsonl |
| `generate_revision_briefs` | critiques_seed | revision_briefs_seed.jsonl |
| `generate_poet_pairs` | briefs + revision_briefs | pairs.jsonl |

**Easier (Sonnet):**
| Script | Input | Output |
|--------|-------|--------|
| `generate_briefs` | raw good | briefs.jsonl |
| `generate_autopsies` | raw bad | autopsies.jsonl |
| `generate_lessons` | craft questions | lessons.jsonl |

```bash
# Full run
python scripts/data_generation/generate_critiques_seed.py --limit-good 200
python scripts/data_generation/generate_comparisons.py
python scripts/data_generation/generate_revision_briefs.py --limit 50
python scripts/data_generation/generate_briefs.py --input data/raw/good --limit 200
python scripts/data_generation/generate_autopsies.py
python scripts/data_generation/generate_lessons.py --limit 10
python scripts/data_generation/generate_poet_pairs.py
```

### 2. Prepare training data

```bash
python scripts/data_generation/prepare_training_data.py [--educator-only] [--poet-only] [--min-samples N] [--seed N]
```

Combines outputs into chat format. `--min-samples N`: requires ≥N examples; if set, caps train/valid to N (quick test). Omit for full run.

### 3. Upload to Modal

```bash
python scripts/modal/upload_data.py
```

Uploads `data/educator_training/{train,valid}.jsonl` and `data/poet_training/{train,valid}.jsonl` to `poetry-data` volume.

### 4. Train + export (Modal)

```bash
# Educator
modal run scripts/modal/train_educator.py [--num-epochs-override N]
modal run scripts/modal/export_gguf.py::export_educator

# Poet
modal run scripts/modal/train_poet.py [--num-epochs-override N]
modal run scripts/modal/export_gguf.py::export_poet

# Or orchestrate both
modal run scripts/modal/modal_app.py [--educator-only] [--poet-only] [--train-only] [--num-epochs N]
```

### 5. Download + inference

```bash
modal volume get --force poetry-gguf qwen2.5-7b-educator-Q4_K_M.gguf models/
modal volume get --force poetry-gguf qwen2.5-7b-poet-Q4_K_M.gguf models/

python scripts/inference/pipeline.py "Write a poem about winter light" [--config PATH]
```

**Reference chat server:** Any client can call the educator via HTTP. Run `python serve_gpm.py [port]` (default 11435). `POST /api/chat` with JSON `{ "messages": [ {"role":"user","content":"..."} ] }` for streaming completion (application/x-ndjson).

## Full workflow

```bash
./scripts/run_full_workflow.sh
```

Runs: critiques_seed + comparisons + revision_briefs (Opus) → briefs + autopsies + lessons (Sonnet) → poet_pairs (Opus) → prepare → upload → train both → export → download. Use `--skip-generation` if `train.jsonl` already exists.

## First test

```bash
./scripts/run_first_test.sh
```

Runs: minimal data (5 bad + 5 good critiques, 5 comparisons, 5 revision briefs, 5 briefs, 5 autopsies, 5 lessons, 10 poet pairs) → prepare (`--min-samples 5`) → upload → train both (1 epoch) → export → inference. Skips if `train.jsonl` exists.

## Optional: Rhyme-focused poet

Train a poet with stronger rhyme/meter using curated poem pairs: `config/rhyme_training.yaml`, `scripts/data_generation/prepare_rhyme_training_data.py`, `scripts/modal/train_rhyme_poet.py`. Data lives in `data/rhyme_training/` (train.jsonl, valid.jsonl). Eval/selection: `scripts/eval/select_strong_rhyme_poems.py`, `scripts/eval/rhyme_analyzer.py`, `scripts/eval/meter_analyzer.py`.

## Config

| File | Purpose |
|------|---------|
| `config/educator_training.yaml` | QLoRA (r=64, α=128, 4 epochs, max_seq 1024) |
| `config/poet_training.yaml` | QLoRA (r=64, α=128, 6 epochs, max_seq 512) |
| `config/rhyme_training.yaml` | Optional rhyme poet QLoRA / data mix |
| `config/export_pipeline.yaml` | Merge + GGUF Q4_K_M |
| `config/inference_config.yaml` | llama.cpp n_ctx, temperature, etc. |
| `config/model_registry.yaml` | Base model registry and fit guidance |
| `config/data_generation.yaml` | Data generation defaults |

## Structure

```
data/raw/{good,bad}/     # Poetry input
data/annotated/          # Claude outputs (critiques, autopsies, comparisons)
data/educator_training/  # train.jsonl, valid.jsonl
data/poet_training/      # train.jsonl, valid.jsonl
data/rhyme_training/     # optional rhyme poet data
persona/                 # educator_neutral.txt, persona_condensed.txt
adapters/                # optional LoRA adapters (e.g. poet_rhyme)
config/                  # YAML configs
scripts/{data_generation,modal,eval,inference,training}/
serve_gpm.py             # Reference HTTP chat server (POST /api/chat)
```

**Alternative inference:** If both models don’t fit in memory (e.g. 32B poet), use `scripts/inference/swapping_pipeline.py` to load one model at a time.

**Eval:** `scripts/eval/` includes rhyme/meter analysis and form registry. `generation_quality.py` and `quant_preservation.py` are placeholders (not yet implemented).
